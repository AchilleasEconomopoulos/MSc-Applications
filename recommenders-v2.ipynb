{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863f3c51",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97e05efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2bcf0",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fafce2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "\n",
    "artists = pd.read_csv(\"data/artists.dat\", delimiter='\\t')\n",
    "tags = pd.read_csv(\"data/tags.dat\", delimiter='\\t')\n",
    "users_artists = pd.read_csv(\"data/user_artists.dat\", delimiter='\\t')\n",
    "users_friends = pd.read_csv(\"data/user_friends.dat\", delimiter='\\t')\n",
    "users_taggedartists = pd.read_csv(\"data/user_taggedartists.dat\", delimiter='\\t')\n",
    "users_taggedartists_time = pd.read_csv(\"data/user_taggedartists-timestamps.dat\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13319070",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ab7bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll consider an artistID as valid if:\n",
    "#   1. They've had minimal interaction with any userID\n",
    "#   2. We have metadata for that artistID\n",
    "valid_artists = set(users_artists['artistID']).intersection(set(artists['id']))\n",
    "\n",
    "# Drop any rows with invalid artistIDs from the user-artist-tag matrix\n",
    "#   i.e. We can't do CBF with an artist we don't have listening time for or that we can't visualize later on\n",
    "users_taggedartists = users_taggedartists[users_taggedartists['artistID'].isin(valid_artists)]\n",
    "users_artists = users_artists[users_artists['artistID'].isin(valid_artists)]\n",
    "\n",
    "\n",
    "# Making sure we have metadata for tags (for visualization later)\n",
    "valid_tags = set(users_taggedartists['tagID'])\n",
    "users_taggedartists = users_taggedartists[users_taggedartists['tagID'].isin(valid_tags)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244c81e",
   "metadata": {},
   "source": [
    "## Load artist and user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d4e9483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting off, look into the user-artist-tag table to extract artist and tag IDs\n",
    "cb_artist_ids = set(users_taggedartists['artistID'])\n",
    "tag_ids = set(users_taggedartists['tagID'])\n",
    "\n",
    "\n",
    "# Do the same for CF. Also the final userset comes from this matrix.\n",
    "#   i.e. these are the users that we'll train and test the system on\n",
    "cf_artist_ids = set(users_artists['artistID'])\n",
    "user_ids = set(users_artists['userID'])\n",
    "\n",
    "# Then cross-check cf_artists with the artist table (need metadata to visualize)\n",
    "cf_artist_ids = cf_artist_ids.intersection(set(artists['id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19059b47",
   "metadata": {},
   "source": [
    "## Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72d065cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 92834\n",
      "Train set size: 90957 -> 0.98\n",
      "Train set size: 1877 -> 0.02\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, group in users_artists.groupby('userID'):\n",
    "\n",
    "    # Minimum threshold to consider a user's data impactful\n",
    "    if len(group) < 5:\n",
    "        train_list.append(group)\n",
    "    else:\n",
    "        train, test = train_test_split(group, test_size=1, random_state=42)\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "# Concatenate final datasets\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "print(f\"Full dataset size: {len(users_artists)}\")\n",
    "print(f\"Train set size: {len(train_df)} -> {len(train_df)/len(users_artists):.2f}\")\n",
    "print(f\"Train set size: {len(test_df)} -> {len(test_df)/len(users_artists):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3a3d1",
   "metadata": {},
   "source": [
    "## Artists - Tags Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90979160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an artists-tags dict\n",
    "tag_N = len(tag_ids)\n",
    "artists_tags_dict = {k: np.full(tag_N,np.nan) for k in cb_artist_ids}\n",
    "# Mapping between the tag_id actual values and their indexes in a list\n",
    "tagmap = {tag_id: tag_idx for tag_idx, tag_id in enumerate(tag_ids)}\n",
    "\n",
    "grouped = (users_taggedartists.groupby(['artistID','tagID']).size().to_dict())\n",
    "for (artist_id,tag_id) , count in grouped.items():\n",
    "    artists_tags_dict[artist_id][tagmap[tag_id]] = count\n",
    "\n",
    "for artist_id, raw_tag_counts in artists_tags_dict.items():\n",
    "    artists_tags_dict[artist_id] = raw_tag_counts/np.nanmax(raw_tag_counts)\n",
    "\n",
    "# Dict -> DF -> numpy Array for better calculations\n",
    "intermediate_df = pd.DataFrame(data=artists_tags_dict)\n",
    "array = np.array(intermediate_df)\n",
    "\n",
    "N = len(cb_artist_ids)\n",
    "for idx, tag_tfs in enumerate(array):\n",
    "    idf = np.log(N/np.sum(~np.isnan(tag_tfs)))\n",
    "    array[idx] = tag_tfs * idf\n",
    "\n",
    "\n",
    "# Back to DF for interpretability\n",
    "artists_tags_df = pd.DataFrame(data=array.transpose(), index=list(cb_artist_ids))\n",
    "artists_tags_df.columns = list(tag_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f7f73",
   "metadata": {},
   "source": [
    "## Users - Artists - Listening times for Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c814295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Mapping the list index of the artistIDs to the actual values\n",
    "cb_artist_reverse_map = {idx : artist_id for idx, artist_id in enumerate(cb_artist_ids)}\n",
    "\n",
    "# Dict to keep each user's training set interactions PLUS the minmax scaler fit for their specific listening times\n",
    "user_weights = {}\n",
    "for idx, row in train_df.iterrows():\n",
    "    artist_id = row['artistID']\n",
    "    user_id = row['userID']\n",
    "    weight = row['weight']\n",
    "\n",
    "    log_weight = np.log1p(weight)   # Log scaling to keep the impact of very high weights \n",
    "\n",
    "    if(user_id in user_weights.keys()):\n",
    "        user_weights[user_id]['weights'][artist_id] = log_weight\n",
    "    else:\n",
    "        user_weights[user_id] = {\n",
    "            'weights': {\n",
    "                artist_id: log_weight\n",
    "            },\n",
    "            'scaler' : MinMaxScaler()\n",
    "        }\n",
    "\n",
    "# Fit each user's minmax scaler and transform the training log weights\n",
    "# for user_id, items in user_weights.items():\n",
    "#     weights = items['weights']\n",
    "#     scaler = items['scaler']\n",
    "    \n",
    "#     scaler.fit(np.array(list(weights.values())).reshape(-1,1))    # Scaling on the weights to help with rating prediction\n",
    "\n",
    "#     for artist_id, weight in weights.items():\n",
    "#         user_weights[user_id]['weights'][artist_id] = scaler.transform(np.array(weight).reshape(1,-1))\n",
    "\n",
    "\n",
    "# Now create a dict to keep each user's test set interactions scaled by their specific scaler\n",
    "user_weights_test = {}\n",
    "for idx, row in test_df.iterrows():\n",
    "    artist_id = row['artistID']\n",
    "    user_id = row['userID']\n",
    "    weight = row['weight']\n",
    "\n",
    "    scaler = user_weights[user_id]['scaler']\n",
    "    log_weight = np.log1p(weight)   # Log scaling to keep the impact of very high weights \n",
    "    # scaled_weight = scaler.transform(np.array(log_weight).reshape(1,-1))\n",
    "\n",
    "\n",
    "    if(user_id in user_weights_test.keys()):\n",
    "        user_weights_test[user_id]['weights'][artist_id] = log_weight\n",
    "    else:\n",
    "        user_weights_test[user_id] = {\n",
    "            'weights': {                        # Keeping dict structure consistent between train and test\n",
    "                artist_id: log_weight\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff293496",
   "metadata": {},
   "source": [
    "## Build user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ea85772",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = {}\n",
    "\n",
    "for user_id in user_weights.keys():\n",
    "    user_profile = np.zeros(len(tag_ids))\n",
    "    for artist_id, weight in user_weights[user_id]['weights'].items():\n",
    "\n",
    "        # artist has to be tagged\n",
    "        if(artist_id in cb_artist_ids):\n",
    "            artist_profile = np.nan_to_num(artists_tags_df.loc[artist_id],0)\n",
    "            user_profile += weight.item() * artist_profile\n",
    "\n",
    "    user_profiles[user_id] = user_profile.reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b425a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The recommendation method\n",
    "def recommend_cbf(user_id,k=1,new_only=True):\n",
    "    if(user_id in user_ids):\n",
    "        recommendations = { 'artist_ids': [], 'similarities': []}\n",
    "        user_profile = user_profiles[user_id]\n",
    "\n",
    "        similarities = cosine_similarity(user_profile.reshape(1,-1),artists_tags_df.fillna(0))   # Returns cos similarities with every row\n",
    "        top_sim = np.argsort(similarities[0])[::-1]                                              # Sorts the indexes in descending order\n",
    "\n",
    "        count = 0\n",
    "        i = 0\n",
    "\n",
    "        while count < k and i<len(top_sim):\n",
    "            idx = top_sim[i]\n",
    "            artist_id = cb_artist_reverse_map[idx]\n",
    "\n",
    "            # Choose whether the recommendation is something that the user has never interacted with\n",
    "            if (new_only):\n",
    "                if (artist_id not in user_weights[user_id]['weights'].keys()):\n",
    "                    recommendations['artist_ids'].append(artist_id)\n",
    "                    recommendations['similarities'].append(similarities[:,idx])\n",
    "                    count+=1\n",
    "\n",
    "            # Otherwise recommendations may contain artists the user has already interacted with\n",
    "            else:\n",
    "                recommendations['artist_ids'].append(artist_id)\n",
    "                recommendations['similarities'].append(similarities[:,idx])\n",
    "                count+=1\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        return recommendations\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_similarity(user_id,artist_id):\n",
    "    sim_score = cosine_similarity(user_profiles[user_id],np.nan_to_num(artists_tags_df.loc[artist_id],0).reshape(1,-1))\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a24d13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77b74c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045a2ec",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2af3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the artist-user interactions with NaNs\n",
    "cf_users_weights = {user_id: np.full(len(cf_artist_ids),np.nan) for user_id in user_ids}\n",
    "\n",
    "artistmap = {artist_id:idx for idx,artist_id in enumerate(cf_artist_ids)}\n",
    "\n",
    "# Fill in the corresponding cells with the user-artist log transformed weights (from the train dataset)\n",
    "for idx, row in train_df.iterrows():\n",
    "    artist_id = row['artistID']\n",
    "    user_id = row['userID']\n",
    "    weight = row['weight']\n",
    "\n",
    "    cf_users_weights[user_id][artistmap[artist_id]] = np.log1p(weight)\n",
    "\n",
    "# Convert dict to DF for easy kNN calculation\n",
    "cf_df = pd.DataFrame(cf_users_weights,index=list(cf_artist_ids))\n",
    "\n",
    "# Subtract the mean for each artist -- REMOVED: not as good for implicit feedback\n",
    "# means = cf_df.mean(axis='columns', skipna=True)\n",
    "# cf_df = cf_df.sub(means.values, axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6bb73",
   "metadata": {},
   "source": [
    "### k-NN calculation for each artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84c12417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate each artist's k-Nearest Neighbors\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k = 50\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine', algorithm='brute')\n",
    "nbrs.fit(cf_df.fillna(0))\n",
    "distances, indices = nbrs.kneighbors(cf_df.fillna(0))\n",
    "\n",
    "similarities = 1 - distances[:, 1:]\n",
    "neighbor_indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be6c3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_artist_map = {idx : artist_id for idx, artist_id in enumerate(cf_artist_ids)}\n",
    "\n",
    "mapped_neighbor_indices = np.vectorize(cf_artist_map.get)(neighbor_indices)\n",
    "\n",
    "neighbor_df = pd.DataFrame(\n",
    "    mapped_neighbor_indices,\n",
    "    columns=[f'neighbor_{i+1}' for i in range(k)],\n",
    "    index=cf_df.index\n",
    ")\n",
    "\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarities,\n",
    "    columns=[f'similarity_{i+1}' for i in range(k)],\n",
    "    index=cf_df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7748c7",
   "metadata": {},
   "source": [
    "### CF recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6ff55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cf(user_id,k=1,new_only=True):\n",
    "    if(user_id in user_ids):\n",
    "        user_dict = user_weights[user_id]['weights']\n",
    "        predictions = []\n",
    "        neighbours_used = []\n",
    "        recommendations = {'artist_ids': [], 'predictions':[], 'neighbours_used':[]}\n",
    "        for artist_id in cf_artist_ids:\n",
    "            if(new_only and artist_id in user_dict.keys()):\n",
    "                predictions.append(-100)\n",
    "                neighbours_used.append(-1)\n",
    "            else:\n",
    "                neighbors = neighbor_df.loc[artist_id]\n",
    "                similarities = similarity_df.loc[artist_id]\n",
    "\n",
    "                nbr_contributions = []\n",
    "\n",
    "                for idx, nbr_artist in enumerate(neighbors):\n",
    "                    if(nbr_artist) in user_dict.keys():\n",
    "                        nbr_contributions.append(user_dict[nbr_artist] * similarities.iloc[idx])\n",
    "\n",
    "                pred_value = 0\n",
    "                if(len(nbr_contributions) > 2):\n",
    "                    pred_value = np.sum(nbr_contributions)/len(nbr_contributions)\n",
    "\n",
    "                predictions.append(pred_value)\n",
    "                neighbours_used.append(len(nbr_contributions))\n",
    "\n",
    "        top_pred_indices = np.argsort(predictions)[::-1]\n",
    "\n",
    "        for idx in top_pred_indices[:k]:\n",
    "            recommendations['artist_ids'].append(cf_artist_map[idx])\n",
    "            recommendations['predictions'].append(predictions[idx])\n",
    "            recommendations['neighbours_used'].append(neighbours_used[idx])\n",
    "            \n",
    "        return recommendations\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08501c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id           name                                     url  \\\n",
      "49  55  Kylie Minogue  http://www.last.fm/music/Kylie+Minogue   \n",
      "\n",
      "                                           pictureURL  \n",
      "49  http://userserve-ak.last.fm/serve/252/12740835...  \n",
      "    id     name                               url  \\\n",
      "61  67  Madonna  http://www.last.fm/music/Madonna   \n",
      "\n",
      "                                          pictureURL  \n",
      "61  http://userserve-ak.last.fm/serve/252/340387.jpg  \n",
      "    id       name                                 url  \\\n",
      "83  89  Lady Gaga  http://www.last.fm/music/Lady+Gaga   \n",
      "\n",
      "                                           pictureURL  \n",
      "83  http://userserve-ak.last.fm/serve/252/47390093...  \n",
      "      id       name                                 url  \\\n",
      "224  230  Green Day  http://www.last.fm/music/Green+Day   \n",
      "\n",
      "                                            pictureURL  \n",
      "224  http://userserve-ak.last.fm/serve/252/15291249...  \n",
      "      id          name                                    url  \\\n",
      "251  257  Mariah Carey  http://www.last.fm/music/Mariah+Carey   \n",
      "\n",
      "                                            pictureURL  \n",
      "251  http://userserve-ak.last.fm/serve/252/4230813.jpg  \n",
      "      id     name                               url  \\\n",
      "282  288  Rihanna  http://www.last.fm/music/Rihanna   \n",
      "\n",
      "                                            pictureURL  \n",
      "282  http://userserve-ak.last.fm/serve/252/53023109...  \n",
      "      id            name                                      url  \\\n",
      "283  289  Britney Spears  http://www.last.fm/music/Britney+Spears   \n",
      "\n",
      "                                            pictureURL  \n",
      "283  http://userserve-ak.last.fm/serve/252/60126439...  \n",
      "      id                name                                          url  \\\n",
      "286  292  Christina Aguilera  http://www.last.fm/music/Christina+Aguilera   \n",
      "\n",
      "                                            pictureURL  \n",
      "286  http://userserve-ak.last.fm/serve/252/47363849...  \n",
      "      id            name                                      url  \\\n",
      "287  293  Ashlee Simpson  http://www.last.fm/music/Ashlee+Simpson   \n",
      "\n",
      "                                            pictureURL  \n",
      "287  http://userserve-ak.last.fm/serve/252/33543587...  \n",
      "      id     name                                    url  \\\n",
      "289  295  Beyoncé  http://www.last.fm/music/Beyonc%C3%A9   \n",
      "\n",
      "                                            pictureURL  \n",
      "289  http://userserve-ak.last.fm/serve/252/61958009...  \n",
      "      id        name                                  url  \\\n",
      "294  300  Katy Perry  http://www.last.fm/music/Katy+Perry   \n",
      "\n",
      "                                            pictureURL  \n",
      "294  http://userserve-ak.last.fm/serve/252/42128121...  \n",
      "      id  name                              url  \\\n",
      "296  302  P!nk  http://www.last.fm/music/P%21nk   \n",
      "\n",
      "                                            pictureURL  \n",
      "296  http://userserve-ak.last.fm/serve/252/56011579...  \n",
      "      id         name                                   url  \\\n",
      "312  318  Hilary Duff  http://www.last.fm/music/Hilary+Duff   \n",
      "\n",
      "                                            pictureURL  \n",
      "312  http://userserve-ak.last.fm/serve/252/8182513.jpg  \n",
      "      id            name                                      url  \\\n",
      "319  325  Ashley Tisdale  http://www.last.fm/music/Ashley+Tisdale   \n",
      "\n",
      "                                            pictureURL  \n",
      "319  http://userserve-ak.last.fm/serve/252/62194153...  \n",
      "      id          name                                    url  \\\n",
      "322  328  David Guetta  http://www.last.fm/music/David+Guetta   \n",
      "\n",
      "                                            pictureURL  \n",
      "322  http://userserve-ak.last.fm/serve/252/43155097...  \n",
      "      id           name                                     url  \\\n",
      "326  332  Kelly Rowland  http://www.last.fm/music/Kelly+Rowland   \n",
      "\n",
      "                                            pictureURL  \n",
      "326  http://userserve-ak.last.fm/serve/252/49377641...  \n",
      "      id           name                                     url  \\\n",
      "327  333  Avril Lavigne  http://www.last.fm/music/Avril+Lavigne   \n",
      "\n",
      "                                            pictureURL  \n",
      "327  http://userserve-ak.last.fm/serve/252/59708309...  \n",
      "      id                name                                          url  \\\n",
      "343  349  The Pussycat Dolls  http://www.last.fm/music/The+Pussycat+Dolls   \n",
      "\n",
      "                                            pictureURL  \n",
      "343  http://userserve-ak.last.fm/serve/252/31329805...  \n",
      "      id   name                               url  \\\n",
      "460  466  Ke$ha  http://www.last.fm/music/Ke%24ha   \n",
      "\n",
      "                                            pictureURL  \n",
      "460  http://userserve-ak.last.fm/serve/252/47829587...  \n",
      "      id   name                             url  \\\n",
      "479  485  Kelis  http://www.last.fm/music/Kelis   \n",
      "\n",
      "                                            pictureURL  \n",
      "479  http://userserve-ak.last.fm/serve/252/51593689...  \n",
      "      id           name                                     url  \\\n",
      "517  523  Lindsay Lohan  http://www.last.fm/music/Lindsay+Lohan   \n",
      "\n",
      "                                            pictureURL  \n",
      "517  http://userserve-ak.last.fm/serve/252/49266505...  \n",
      "      id          name                                    url  \\\n",
      "518  524  Jeffree Star  http://www.last.fm/music/Jeffree+Star   \n",
      "\n",
      "                                            pictureURL  \n",
      "518  http://userserve-ak.last.fm/serve/252/49725955...  \n",
      "      id     name                               url  \\\n",
      "520  526  La Roux  http://www.last.fm/music/La+Roux   \n",
      "\n",
      "                                            pictureURL  \n",
      "520  http://userserve-ak.last.fm/serve/252/30382691...  \n",
      "      id          name                                    url  \\\n",
      "526  532  Little Boots  http://www.last.fm/music/Little+Boots   \n",
      "\n",
      "                                            pictureURL  \n",
      "526  http://userserve-ak.last.fm/serve/252/30669737...  \n",
      "      id                 name                                           url  \\\n",
      "529  535  Sophie Ellis-Bextor  http://www.last.fm/music/Sophie+Ellis-Bextor   \n",
      "\n",
      "                                            pictureURL  \n",
      "529  http://userserve-ak.last.fm/serve/252/61811325...  \n",
      "      id            name                                      url  \\\n",
      "530  536  Good Charlotte  http://www.last.fm/music/Good+Charlotte   \n",
      "\n",
      "                                            pictureURL  \n",
      "530  http://userserve-ak.last.fm/serve/252/55721971...  \n",
      "      id          name                                    url  \\\n",
      "538  544  Adam Lambert  http://www.last.fm/music/Adam+Lambert   \n",
      "\n",
      "                                            pictureURL  \n",
      "538  http://userserve-ak.last.fm/serve/252/56430315...  \n",
      "      id      name                                url  \\\n",
      "539  545  Flo Rida  http://www.last.fm/music/Flo+Rida   \n",
      "\n",
      "                                            pictureURL  \n",
      "539  http://userserve-ak.last.fm/serve/252/52067183...  \n",
      "      id            name                                      url  \\\n",
      "542  548  Ellie Goulding  http://www.last.fm/music/Ellie+Goulding   \n",
      "\n",
      "                                            pictureURL  \n",
      "542  http://userserve-ak.last.fm/serve/252/62251875...  \n",
      "      id     name                               url  \\\n",
      "695  701  Shakira  http://www.last.fm/music/Shakira   \n",
      "\n",
      "                                            pictureURL  \n",
      "695  http://userserve-ak.last.fm/serve/252/52116105...  \n",
      "      id            name                                      url  \\\n",
      "789  798  Geri Halliwell  http://www.last.fm/music/Geri+Halliwell   \n",
      "\n",
      "                                            pictureURL  \n",
      "789  http://userserve-ak.last.fm/serve/252/51629225...  \n",
      "      id        name                                  url  \\\n",
      "877  886  Dragonette  http://www.last.fm/music/Dragonette   \n",
      "\n",
      "                                            pictureURL  \n",
      "877  http://userserve-ak.last.fm/serve/252/44153343...  \n",
      "      id           name                                     url  \\\n",
      "894  903  Amy Winehouse  http://www.last.fm/music/Amy+Winehouse   \n",
      "\n",
      "                                           pictureURL  \n",
      "894  http://userserve-ak.last.fm/serve/252/366300.jpg  \n",
      "      id             name                                       url  \\\n",
      "906  915  Alexandra Burke  http://www.last.fm/music/Alexandra+Burke   \n",
      "\n",
      "                                            pictureURL  \n",
      "906  http://userserve-ak.last.fm/serve/252/54753767...  \n",
      "        id      name                                url  \\\n",
      "1053  1062  Ladytron  http://www.last.fm/music/Ladytron   \n",
      "\n",
      "                                             pictureURL  \n",
      "1053  http://userserve-ak.last.fm/serve/252/15387769...  \n",
      "        id        name                                  url  \\\n",
      "1442  1451  Girlicious  http://www.last.fm/music/Girlicious   \n",
      "\n",
      "                                             pictureURL  \n",
      "1442  http://userserve-ak.last.fm/serve/252/29705685...  \n",
      "        id               name                                         url  \\\n",
      "1447  1456  Far East Movement  http://www.last.fm/music/Far+East+Movement   \n",
      "\n",
      "                                             pictureURL  \n",
      "1447  http://userserve-ak.last.fm/serve/252/53131319...  \n",
      "        id          name                                    url  \\\n",
      "1571  1580  Paris Hilton  http://www.last.fm/music/Paris+Hilton   \n",
      "\n",
      "                                             pictureURL  \n",
      "1571  http://userserve-ak.last.fm/serve/252/46684167...  \n",
      "        id       name                                 url  \\\n",
      "2003  2018  September  http://www.last.fm/music/September   \n",
      "\n",
      "                                             pictureURL  \n",
      "2003  http://userserve-ak.last.fm/serve/252/58563833...  \n",
      "        id    name                              url  \\\n",
      "2068  2083  M.I.A.  http://www.last.fm/music/M.I.A.   \n",
      "\n",
      "                                             pictureURL  \n",
      "2068  http://userserve-ak.last.fm/serve/252/18291007...  \n",
      "        id   name                             url  \\\n",
      "2504  2521  Robyn  http://www.last.fm/music/Robyn   \n",
      "\n",
      "                                             pictureURL  \n",
      "2504  http://userserve-ak.last.fm/serve/252/53752943...  \n",
      "        id          name                                    url  \\\n",
      "3360  3397  Heidi Montag  http://www.last.fm/music/Heidi+Montag   \n",
      "\n",
      "                                             pictureURL  \n",
      "3360  http://userserve-ak.last.fm/serve/252/55539661...  \n",
      "        id           name                                               url  \\\n",
      "3465  3502  Róisín Murphy  http://www.last.fm/music/R%C3%B3is%C3%ADn+Murphy   \n",
      "\n",
      "                                             pictureURL  \n",
      "3465  http://userserve-ak.last.fm/serve/252/57114367...  \n",
      "        id        name                                  url  \\\n",
      "5801  5926  The Sounds  http://www.last.fm/music/The+Sounds   \n",
      "\n",
      "                                             pictureURL  \n",
      "5801  http://userserve-ak.last.fm/serve/252/50507047...  \n",
      "        id       name                                 url  \\\n",
      "7149  7301  Ian Carey  http://www.last.fm/music/Ian+Carey   \n",
      "\n",
      "                                             pictureURL  \n",
      "7149  http://userserve-ak.last.fm/serve/252/53491009...  \n",
      "          id  name                            url  \\\n",
      "12103  12550  Sono  http://www.last.fm/music/Sono   \n",
      "\n",
      "                                              pictureURL  \n",
      "12103  http://userserve-ak.last.fm/serve/252/2226743.jpg  \n",
      "          id            name                                      url  \\\n",
      "14456  15168  Marcio Mathers  http://www.last.fm/music/Marcio+Mathers   \n",
      "\n",
      "                                              pictureURL  \n",
      "14456  http://userserve-ak.last.fm/serve/252/57481261...  \n",
      "          id         name                                   url  \\\n",
      "14755  15510  Randy Orton  http://www.last.fm/music/Randy+Orton   \n",
      "\n",
      "                                              pictureURL  \n",
      "14755  http://userserve-ak.last.fm/serve/252/57280719...  \n",
      "          id        name                                  url  \\\n",
      "14756  15511  Jared Leto  http://www.last.fm/music/Jared+Leto   \n",
      "\n",
      "                                              pictureURL  \n",
      "14756  http://userserve-ak.last.fm/serve/252/43777271...  \n",
      "          id         name                                             url  \\\n",
      "14757  15512  Os + De Mil  http://www.last.fm/music/Os%2B%252B%2BDe%2BMil   \n",
      "\n",
      "                                              pictureURL  \n",
      "14757  http://userserve-ak.last.fm/serve/252/47402439...  \n"
     ]
    }
   ],
   "source": [
    "rows = users_artists[users_artists['userID']==1600]\n",
    "\n",
    "for idx,row in rows.iterrows():\n",
    "    print(artists[artists['id']==row['artistID']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126ae9b",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6055d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cf():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    impossible_predictions = 0\n",
    "    count=0\n",
    "    for idx,row in (test_df.iterrows()):\n",
    "        artist_id = row['artistID']\n",
    "        user_id = row['userID']\n",
    "        weight = row['weight']\n",
    "\n",
    "        y_true.append(np.log1p(weight))\n",
    "\n",
    "        neighbors = neighbor_df.loc[artist_id]\n",
    "        similarities = similarity_df.loc[artist_id]\n",
    "\n",
    "        user_dict = user_weights[user_id]['weights']\n",
    "\n",
    "        nbr_contributions = []\n",
    "\n",
    "        for idx, nbr_artist in enumerate(neighbors):\n",
    "            if(nbr_artist) in user_dict.keys():\n",
    "                nbr_contributions.append(user_dict[nbr_artist] * similarities.iloc[idx])\n",
    "\n",
    "        pred_value = 0\n",
    "\n",
    "        # If we can't find any user interaction with any of the most similar artists, the prediction is impossible\n",
    "        if(nbr_contributions):\n",
    "            pred_value = np.sum(nbr_contributions)/len(nbr_contributions)\n",
    "            y_pred.append(pred_value)\n",
    "        else:\n",
    "            impossible_predictions+=1\n",
    "            y_true.pop()\n",
    "\n",
    "\n",
    "    return y_true,y_pred, impossible_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b06f2",
   "metadata": {},
   "source": [
    "### Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "81b25735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 -> 0.15\n",
      "3.9801906112721963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_true, y_pred_cf, impossible = evaluate_cf()\n",
    "print(f\"{impossible} -> {impossible/(len(y_true)+impossible):.2f}\")\n",
    "print(root_mean_squared_error(y_true,y_pred_cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fae85168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(user_id, k=1, new_only=True):\n",
    "    \n",
    "    cf_rec = recommend_cf(user_id,k,new_only)\n",
    "    \n",
    "    cbf_rec = recommend_cbf(user_id,k,new_only)\n",
    "\n",
    "    num_of_interactions = np.sum(~np.isnan(cf_df[user_id]))\n",
    "    # If no collaborative data available, use pure content-based\n",
    "\n",
    "\n",
    "    if not cf_rec or num_of_interactions<5 or cf_rec['predictions'][0] < 3.5:\n",
    "        if cbf_rec:\n",
    "            return cbf_rec\n",
    "    \n",
    "    else:\n",
    "        return cf_rec\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79009cd2",
   "metadata": {},
   "source": [
    "## Precision @ top10 for CBF, CF, Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3804840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 704/1877 [44:52<1:14:46,  3.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m cbf_pred = recommend_cbf(user_id,\u001b[32m10\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33martist_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m cf_pred = recommend_cf(user_id,\u001b[32m10\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33martist_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m hybrid_pred = \u001b[43mrecommend_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33martist_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m hits_cbf = \u001b[38;5;28mlen\u001b[39m(relevant_artists & cbf_pred)\n\u001b[32m     14\u001b[39m hits_cf = \u001b[38;5;28mlen\u001b[39m(relevant_artists & cf_pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mrecommend_hybrid\u001b[39m\u001b[34m(user_id, k, new_only)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrecommend_hybrid\u001b[39m(user_id, k=\u001b[32m1\u001b[39m, new_only=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      3\u001b[39m     cf_rec = recommend_cf(user_id,k,new_only)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     cbf_rec = \u001b[43mrecommend_cbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     num_of_interactions = np.sum(~np.isnan(cf_df[user_id]))\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# If no collaborative data available, use pure content-based\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mrecommend_cbf\u001b[39m\u001b[34m(user_id, k, new_only)\u001b[39m\n\u001b[32m      4\u001b[39m recommendations = { \u001b[33m'\u001b[39m\u001b[33martist_ids\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33msimilarities\u001b[39m\u001b[33m'\u001b[39m: []}\n\u001b[32m      5\u001b[39m user_profile = user_profiles[user_id]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m similarities = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_profile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43martists_tags_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Returns cos similarities with every row\u001b[39;00m\n\u001b[32m      8\u001b[39m top_sim = np.argsort(similarities[\u001b[32m0\u001b[39m])[::-\u001b[32m1\u001b[39m]                                              \u001b[38;5;66;03m# Sorts the indexes in descending order\u001b[39;00m\n\u001b[32m     10\u001b[39m count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1747\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(X, Y, dense_output)\u001b[39m\n\u001b[32m   1745\u001b[39m     Y_normalized = X_normalized\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     Y_normalized = \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=dense_output)\n\u001b[32m   1751\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1997\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(X, norm, axis, copy, return_norm)\u001b[39m\n\u001b[32m   1995\u001b[39m     norms = xp.sum(xp.abs(X), axis=\u001b[32m1\u001b[39m)\n\u001b[32m   1996\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m norm == \u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1997\u001b[39m     norms = \u001b[43mrow_norms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m norm == \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1999\u001b[39m     norms = xp.max(xp.abs(X), axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/sklearn/utils/extmath.py:76\u001b[39m, in \u001b[36mrow_norms\u001b[39m\u001b[34m(X, squared)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m     75\u001b[39m     X = np.asarray(X)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     norms = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mij,ij->i\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     norms = xp.asarray(norms)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/env/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:1423\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1422\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1427\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "precisions_cbf = []\n",
    "precisions_cf = []\n",
    "precisions_hybrid = []\n",
    "\n",
    "for user_id, items in tqdm(user_weights_test.items()):\n",
    "    relevant_artists = items['weights'].keys()\n",
    "    cbf_pred = recommend_cbf(user_id,10)['artist_ids']\n",
    "    cf_pred = recommend_cf(user_id,10)['artist_ids']\n",
    "    hybrid_pred = recommend_hybrid(user_id,10)['artist_ids']\n",
    "\n",
    "    hits_cbf = len(relevant_artists & cbf_pred)\n",
    "    hits_cf = len(relevant_artists & cf_pred)\n",
    "    hits_hybrid = len(relevant_artists & hybrid_pred)\n",
    "    \n",
    "    precisions_cbf.append(hits_cbf/10)\n",
    "    precisions_cf.append(hits_cf/10)\n",
    "    precisions_hybrid.append(hits_hybrid/10)\n",
    "\n",
    "precision_at_10_cf = sum(precisions_cf)/len(precisions_cf)\n",
    "precision_at_10_cbf = sum(precisions_cbf)/len(precisions_cbf)\n",
    "precision_at_10_hybrid = sum(precisions_hybrid)/len(precisions_hybrid)\n",
    "\n",
    "print(precision_at_10_cbf)\n",
    "print(precision_at_10_cf)\n",
    "print(precision_at_10_hybrid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093a2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
