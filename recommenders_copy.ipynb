{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863f3c51",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e05efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2bcf0",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafce2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "\n",
    "artists = pd.read_csv(\"data/artists.dat\", delimiter='\\t')\n",
    "tags = pd.read_csv(\"data/tags.dat\", delimiter='\\t')\n",
    "users_artists = pd.read_csv(\"data/user_artists.dat\", delimiter='\\t')\n",
    "users_friends = pd.read_csv(\"data/user_friends.dat\", delimiter='\\t')\n",
    "users_taggedartists = pd.read_csv(\"data/user_taggedartists.dat\", delimiter='\\t')\n",
    "users_taggedartists_time = pd.read_csv(\"data/user_taggedartists-timestamps.dat\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13319070",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab7bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll consider an artistID as valid if:\n",
    "#   1. They've had minimal interaction with any userID\n",
    "#   2. We have metadata for that artistID\n",
    "valid_artists = set(users_artists['artistID']).intersection(set(artists['id']))\n",
    "\n",
    "# Drop any rows with invalid artistIDs from the user-artist-tag matrix\n",
    "#   i.e. We can't do CBF with an artist we don't have listening time for or that we can't visualize later on\n",
    "users_taggedartists = users_taggedartists[users_taggedartists['artistID'].isin(valid_artists)]\n",
    "users_artists = users_artists[users_artists['artistID'].isin(valid_artists)]\n",
    "\n",
    "\n",
    "# Making sure we have metadata for tags (for visualization later)\n",
    "valid_tags = set(users_taggedartists['tagID'])\n",
    "users_taggedartists = users_taggedartists[users_taggedartists['tagID'].isin(valid_tags)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244c81e",
   "metadata": {},
   "source": [
    "## Load artist and user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e9483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting off, look into the user-artist-tag table to extract artist and tag IDs\n",
    "cb_artist_ids = set(users_taggedartists['artistID'])\n",
    "tag_ids = set(users_taggedartists['tagID'])\n",
    "\n",
    "\n",
    "# Do the same for CF. Also the final userset comes from this matrix.\n",
    "#   i.e. these are the users that we'll train and test the system on\n",
    "cf_artist_ids = set(users_artists['artistID'])\n",
    "user_ids = set(users_artists['userID'])\n",
    "\n",
    "# Then cross-check cf_artists with the artist table (need metadata to visualize)\n",
    "cf_artist_ids = cf_artist_ids.intersection(set(artists['id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19059b47",
   "metadata": {},
   "source": [
    "## Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d065cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 92834\n",
      "Train set size: 74256 -> 0.80\n",
      "Train set size: 18578 -> 0.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, group in users_artists.groupby('userID'):\n",
    "\n",
    "    # Minimum threshold to consider a user's data impactful\n",
    "    if len(group) < 5:\n",
    "        train_list.append(group)\n",
    "    else:\n",
    "        train, test = train_test_split(group, test_size=0.2, random_state=42)\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "# Concatenate final datasets\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "print(f\"Full dataset size: {len(users_artists)}\")\n",
    "print(f\"Train set size: {len(train_df)} -> {len(train_df)/len(users_artists):.2f}\")\n",
    "print(f\"Train set size: {len(test_df)} -> {len(test_df)/len(users_artists):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3a3d1",
   "metadata": {},
   "source": [
    "## Artists - Tags Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90979160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an artists-tags dict\n",
    "tag_N = len(tag_ids)\n",
    "artists_tags_dict = {k: np.full(tag_N,np.nan) for k in cb_artist_ids}\n",
    "# Mapping between the tag_id actual values and their indexes in a list\n",
    "tagmap = {tag_id: tag_idx for tag_idx, tag_id in enumerate(tag_ids)}\n",
    "\n",
    "grouped = (users_taggedartists.groupby(['artistID','tagID']).size().to_dict())\n",
    "for (artist_id,tag_id) , count in grouped.items():\n",
    "    artists_tags_dict[artist_id][tagmap[tag_id]] = count\n",
    "\n",
    "for artist_id, raw_tag_counts in artists_tags_dict.items():\n",
    "    artists_tags_dict[artist_id] = raw_tag_counts/np.nanmax(raw_tag_counts)\n",
    "\n",
    "# Dict -> DF -> numpy Array for better calculations\n",
    "intermediate_df = pd.DataFrame(data=artists_tags_dict)\n",
    "array = np.array(intermediate_df)\n",
    "\n",
    "N = len(cb_artist_ids)\n",
    "for idx, tag_tfs in enumerate(array):\n",
    "    idf = np.log(N/np.sum(~np.isnan(tag_tfs)))\n",
    "    array[idx] = tag_tfs * idf\n",
    "\n",
    "\n",
    "# Back to DF for interpretability\n",
    "artists_tags_df = pd.DataFrame(data=array.transpose(), index=list(cb_artist_ids))\n",
    "artists_tags_df.columns = list(tag_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f7f73",
   "metadata": {},
   "source": [
    "## Users - Artists - Listening times for Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c814295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Mapping the list index of the artistIDs to the actual values\n",
    "cb_artist_reverse_map = {idx : artist_id for idx, artist_id in enumerate(cb_artist_ids)}\n",
    "\n",
    "# Dict to keep each user's training set interactions PLUS the minmax scaler fit for their specific listening times\n",
    "user_weights = {}\n",
    "for idx, row in train_df.iterrows():\n",
    "    artist_id = row['artistID']\n",
    "    user_id = row['userID']\n",
    "    weight = row['weight']\n",
    "\n",
    "    log_weight = np.log1p(weight)   # Log scaling to keep the impact of very high weights \n",
    "\n",
    "    if(user_id in user_weights.keys()):\n",
    "        user_weights[user_id]['weights'][artist_id] = weight\n",
    "    else:\n",
    "        user_weights[user_id] = {\n",
    "            'weights': {\n",
    "                artist_id: weight\n",
    "            },\n",
    "            'scaler' : MinMaxScaler()\n",
    "        }\n",
    "\n",
    "# Fit each user's minmax scaler and transform the training log weights\n",
    "for user_id, items in user_weights.items():\n",
    "    weights = items['weights']\n",
    "    scaler = items['scaler']\n",
    "    \n",
    "    scaler.fit(np.array(list(weights.values())).reshape(-1,1))    # Scaling on the weights to help with rating prediction\n",
    "\n",
    "    for artist_id, weight in weights.items():\n",
    "        user_weights[user_id]['weights'][artist_id] = scaler.transform(np.array(weight).reshape(1,-1))\n",
    "\n",
    "\n",
    "# Now create a dict to keep each user's test set interactions scaled by their specific scaler\n",
    "user_weights_test = {}\n",
    "for idx, row in test_df.iterrows():\n",
    "    artist_id = row['artistID']\n",
    "    user_id = row['userID']\n",
    "    weight = row['weight']\n",
    "\n",
    "    scaler = user_weights[user_id]['scaler']\n",
    "    log_weight = np.log1p(weight)   # Log scaling to keep the impact of very high weights \n",
    "    scaled_weight = scaler.transform(np.array(weight).reshape(1,-1))\n",
    "\n",
    "\n",
    "    if(user_id in user_weights_test.keys()):\n",
    "        user_weights_test[user_id]['weights'][artist_id] = scaled_weight\n",
    "    else:\n",
    "        user_weights_test[user_id] = {\n",
    "            'weights': {                        # Keeping dict structure consistent between train and test\n",
    "                artist_id: scaled_weight\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "66d97f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11946\n"
     ]
    }
   ],
   "source": [
    "artist_profile = np.nan_to_num(artists_tags_df.loc[1],0).reshape(-1,1)\n",
    "# print(artist_profile.shape)\n",
    "# print(user_weights[2]['weights'][51].s)\n",
    "# print(artists_tags_df.loc[1][139])\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff293496",
   "metadata": {},
   "source": [
    "## Build user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ea85772",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = {}\n",
    "\n",
    "for user_id in user_weights.keys():\n",
    "    user_profile = np.zeros(len(tag_ids))\n",
    "    for artist_id, weight in user_weights[user_id]['weights'].items():\n",
    "\n",
    "        # artist has to be tagged\n",
    "        if(artist_id in cb_artist_ids):\n",
    "            artist_profile = np.nan_to_num(artists_tags_df.loc[artist_id],0)\n",
    "            user_profile += weight.item() * artist_profile\n",
    "\n",
    "    user_profiles[user_id] = user_profile.reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b425a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The recommendation method\n",
    "def recommend_cbf(user_id,k=1,eval=False):\n",
    "    if(user_id in user_ids):\n",
    "        recommendations = { 'artist_ids': [], 'similarities': []}\n",
    "        user_profile = user_profiles[user_id]\n",
    "\n",
    "        similarities = cosine_similarity(user_profile.reshape(1,-1),artists_tags_df.fillna(0))   # Returns cos similarities with every row\n",
    "        top_sim = np.argsort(similarities[0])[::-1]                                              # Sorts the indexes in descending order\n",
    "\n",
    "        count = 0\n",
    "        i = 0\n",
    "\n",
    "        while count < k and i<len(top_sim):\n",
    "            idx = top_sim[i]\n",
    "            artist_id = cb_artist_reverse_map[idx]\n",
    "\n",
    "            # If we're evaluating, we want similar artists that the user has listened to, in order to calculate a predicted rating\n",
    "            if (not eval):\n",
    "                if (artist_id not in user_weights[user_id]['weights'].keys()):\n",
    "                    recommendations['artist_ids'].append(artist_id)\n",
    "                    recommendations['similarities'].append(similarities[:,idx])\n",
    "                    count+=1\n",
    "\n",
    "            # If not, we're interested only in new artists that the user hasn't listened to before\n",
    "            else:\n",
    "                if(artist_id in user_weights[user_id]['weights'].keys()):\n",
    "                    \n",
    "                    recommendations['artist_ids'].append(artist_id)\n",
    "                    recommendations['similarities'].append(similarities[:,idx])\n",
    "                    count+=1\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        return recommendations\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_similarity(user_id,artist_id):\n",
    "    sim_score = cosine_similarity(user_profiles[user_id],np.nan_to_num(artists_tags_df.loc[artist_id],0).reshape(1,-1))\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9eb48b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1877\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bac5c853",
   "metadata": {},
   "source": [
    "## Precision @ top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfc81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 34/1877 [00:40<35:17,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "precisions = []\n",
    "\n",
    "for user_id, items in tqdm(user_weights_test.items()):\n",
    "    relevant_artists = items['weights'].keys()\n",
    "    predicted_artists = recommend_cbf(user_id,10)['artist_ids']\n",
    "\n",
    "    hits = len(relevant_artists & predicted_artists)\n",
    "    precisions.append(hits/10)\n",
    "\n",
    "precision_at_10 = sum(precisions)/len(precisions)\n",
    "print(precision_at_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05f221",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87565ec",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8328d1",
   "metadata": {},
   "source": [
    "### DF init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_array = np.zeros((len(cf_artist_ids),len(user_ids)))\n",
    "cf_df = pd.DataFrame(cf_array,index=list(cf_artist_ids))\n",
    "cf_df.columns = list(user_ids)\n",
    "\n",
    "for user_id, items in user_weights.items():\n",
    "    for artist_id, weight in items['weights'].items():\n",
    "        cf_df.loc[artist_id,user_id] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8e0fe8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17632\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "856d3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = cf_dataframe.mean(axis=1, skipna=True)\n",
    "new = cf_dataframe.sub(means.values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84c12417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine', algorithm='brute')\n",
    "# nbrs.fit(new.fillna(0))\n",
    "# distances, indices = nbrs.kneighbors(new.fillna(0))\n",
    "nbrs.fit(cf_dataframe)\n",
    "distances, indices = nbrs.kneighbors(cf_dataframe)\n",
    "\n",
    "similarities = 1 - distances[:, 1:]\n",
    "neighbor_indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be6c3397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       neighbor_1  neighbor_2  neighbor_3  neighbor_4  neighbor_5\n",
      "1            5077        5092        5078        5095        5086\n",
      "2            3188        1303        1300        5713        5712\n",
      "3           13677       13679        7925       10894       18730\n",
      "4            9236        9238        9237        9241        9246\n",
      "5           15289        8044        8049        8046        8045\n",
      "...           ...         ...         ...         ...         ...\n",
      "18741       18736       18737       18738       18739       18744\n",
      "18742       18736       18737       18738       18739       18744\n",
      "18743       18736       18737       18738       18739       18744\n",
      "18744       18736       18737       18738       18739       18744\n",
      "18745       18745       11394       18458       15996        3683\n",
      "\n",
      "[17632 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "cf_artist_map = {artist_idx : artist_id for artist_idx, artist_id in enumerate(cf_artist_ids)}\n",
    "mapped_neighbor_indices = np.vectorize(cf_artist_map.get)(neighbor_indices)\n",
    "\n",
    "neighbor_df = pd.DataFrame(\n",
    "    mapped_neighbor_indices,\n",
    "    columns=[f'neighbor_{i+1}' for i in range(k)],\n",
    "    index=cf_dataframe.index\n",
    ")\n",
    "\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarities,\n",
    "    columns=[f'similarity_{i+1}' for i in range(k)],\n",
    "    index=cf_dataframe.index\n",
    ")\n",
    "\n",
    "print(neighbor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for artist_idx, neighbors in neighbor_df.iterrows():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e634675",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dataframe = pd.DataFrame(data=cf_user_artists).transpose()\n",
    "cf_dataframe.columns = list(cf_user_ids)\n",
    "x_split = int(np.floor(len(cf_dataframe)*0.2))\n",
    "y_split = int(np.floor(len(cf_dataframe.columns)*0.2))\n",
    "\n",
    "# print(cf_dataframe)\n",
    "eval_df = cf_dataframe.copy()\n",
    "# print(cf_test_df)\n",
    "eval_df.iloc[-x_split:, -y_split:] = eval_df.iloc[-x_split:, -y_split:].where(eval_df.iloc[-x_split:, -y_split:] == 0, np.nan)\n",
    "\n",
    "print(eval_df.iloc[-x_split:, -y_split:])\n",
    "print(cf_dataframe.iloc[-x_split:, -y_split:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for idx, col in test.items():\n",
    "    if(not np.count_nonzero(col)):\n",
    "        print(col[col>0])\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 20000\n",
    "min_idx = 0\n",
    "for idx,col in cf_dataframe.items():\n",
    "    count = np.count_nonzero(col)\n",
    "    if count <= min_count:\n",
    "        min_count= count\n",
    "        min_idx = idx\n",
    "\n",
    "\n",
    "print(min_count, min_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9490da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae85168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hybrid(user_id, target_artist, listening_df, similarities_df, artist_features_df, \n",
    "                   alpha=0.7, k=5):\n",
    "    \"\"\"\n",
    "    Combine collaborative and content-based predictions\n",
    "    alpha: weight for collaborative filtering (0.7 = 70% collaborative, 30% content)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Try collaborative filtering first\n",
    "    collab_pred = predict_weighted_average(user_id, target_artist, similarities_df, listening_df, k)\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, target_artist, listening_df, artist_features_df)\n",
    "    \n",
    "    # If no collaborative data available, use pure content-based\n",
    "    if collab_pred == 0:\n",
    "        return content_pred\n",
    "    \n",
    "    # If no content data available, use pure collaborative\n",
    "    if content_pred == 0:\n",
    "        return collab_pred\n",
    "    \n",
    "    # Hybrid combination\n",
    "    return alpha * collab_pred + (1 - alpha) * content_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
